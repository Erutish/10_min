{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiM6A4kitQAp",
        "outputId": "f2ec30db-1024-4fa0-c94d-fcf709321517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukZrI-kEouK7",
        "outputId": "8e7ad5f9-fc38-4998-e6bd-745eb893dbd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.8_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.9/292.9 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "!apt-get update -qq && apt-get install -qq poppler-utils\n",
        "!pip install easyocr pdf2image opencv-python pillow --quiet\n",
        "\n",
        "\n",
        "!mkdir -p /root/.EasyOCR/model\n",
        "!wget -q -O /root/.EasyOCR/model/craft_mlt_25k.pth \\\n",
        "    \"https://huggingface.co/xiaoyao9184/easyocr/resolve/master/craft_mlt_25k.pth\"\n",
        "!wget -q -O /root/.EasyOCR/model/bengali.pth \\\n",
        "    \"https://huggingface.co/xiaoyao9184/easyocr/resolve/master/bengali.pth\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import easyocr\n",
        "reader = easyocr.Reader(\n",
        "    ['bn'],\n",
        "    gpu=False,\n",
        "    download_enabled=False,\n",
        "    model_storage_directory='/root/.EasyOCR/model'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM-aRICHpz3n",
        "outputId": "53fac3e6-89a0-4251-8988-d507235fe882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Using CPU. Note: This module is much faster with a GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pdf2image import convert_from_path\n",
        "import cv2, numpy as np, os\n",
        "\n",
        "PDF_PATH = \"/content/drive/MyDrive/MyDrive/Book.pdf\"\n",
        "OUT_DIR = '/content/drive/MyDrive/ocr_output'\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "pages = convert_from_path(PDF_PATH, dpi=300)\n",
        "\n",
        "for i, page in enumerate(pages):\n",
        "    # Preprocess page image\n",
        "    img = cv2.cvtColor(np.array(page), cv2.COLOR_RGB2BGR)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    bw = cv2.adaptiveThreshold(gray, 255,\n",
        "                               cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                               cv2.THRESH_BINARY, 21, 8)\n",
        "\n",
        "    # OCR extraction\n",
        "    text_lines = reader.readtext(bw, detail=0, paragraph=True)\n",
        "    text = \"\\n\".join(text_lines)\n",
        "\n",
        "    # Save output\n",
        "    fn = f'{OUT_DIR}/page_{i+1:03d}.txt'\n",
        "    with open(fn, 'w', encoding='utf-8') as f:\n",
        "        f.write(text)\n",
        "    print(f'✅ Saved: {fn}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkhdz5Edp3xY",
        "outputId": "805f1c0f-aeac-4c27-85a2-581dfae40f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_001.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_002.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_003.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_004.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_005.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_006.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_007.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_008.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_009.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_010.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_011.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_012.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_013.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_014.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_015.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_016.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_017.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_018.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_019.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_020.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_021.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_022.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_023.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_024.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_025.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_026.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_027.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_028.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_029.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_030.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_031.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_032.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_033.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_034.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_035.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_036.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_037.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_038.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_039.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_040.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_041.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_042.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_043.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_044.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_045.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_046.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_047.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_048.txt\n",
            "✅ Saved: /content/drive/MyDrive/ocr_output/page_049.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iik-4UkebP2C",
        "outputId": "ef2567f1-5db2-44bc-b909-08d9aaf5f144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.26.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import os\n",
        "\n",
        "pdf_path = \"/content/drive/MyDrive/MyDrive/Book.pdf\"\n",
        "output_dir = \"/content/drive/MyDrive/normal_pages\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "with fitz.open(pdf_path) as doc:\n",
        "    for i, page in enumerate(doc):\n",
        "        page_text = page.get_text()\n",
        "        with open(f\"{output_dir}/page_{i+1:03d}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(page_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "UaE-4qDlp325"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai --quiet\n",
        "import openai\n",
        "import os\n"
      ],
      "metadata": {
        "id": "BdkM7HMgdOd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "ocr_dir = \"/content/drive/MyDrive/ocr_output\"\n",
        "normal_dir = \"/content/drive/MyDrive/normal_pages\"\n",
        "cleaned_dir = \"/content/drive/MyDrive/cleaned_pages\"\n",
        "os.makedirs(cleaned_dir, exist_ok=True)\n",
        "\n",
        "import os\n",
        "OPENAI_API_KEY= \"\"\n",
        "\n",
        "for i in range(1, 50):\n",
        "    ocr_file = f\"{ocr_dir}/page_{i:03d}.txt\"\n",
        "    normal_file = f\"{normal_dir}/page_{i:03d}.txt\"\n",
        "\n",
        "    # Read both files\n",
        "    with open(ocr_file, encoding=\"utf-8\") as f:\n",
        "        ocr_text = f.read()\n",
        "    with open(normal_file, encoding=\"utf-8\") as f:\n",
        "        normal_text = f.read()\n",
        "\n",
        "    # Compose LLM prompt\n",
        "    prompt = f\"\"\"\n",
        "You are a highly skilled Bangla document reconstruction and cleaning assistant.\n",
        "You are provided with two versions of the same Bangla textbook content:\n",
        "- OCR-extracted text (which may contain recognition errors, missing words, or artifacts)\n",
        "- Direct PDF-extracted text (which may contain gibberish or broken Unicode)\n",
        "\n",
        "Task:\n",
        "- Carefully compare both versions and reconstruct the most accurate, readable, and well-formatted Bangla text.\n",
        "- If you detect that any part of the content is or should be a table, MCQ (multiple choice question), or options for a question, format them properly (use markdown tables, or clear bullet/numbered lists for options and MCQs).\n",
        "- For MCQs: ensure that each question and its options are clearly separated and labeled.\n",
        "- For tables: reconstruct using markdown (| column | column | ...) if possible.\n",
        "- Where both files are noisy, do your best to guess the most plausible reconstruction based on context.\n",
        "- Remove repeated headers, page numbers, and irrelevant artifacts.\n",
        "- Make the paragraphs and lists flow naturally, ready for use in a Bangla knowledge retrieval system.\n",
        "\n",
        "Here are the two versions:\n",
        "[OCR_OUTPUT]\n",
        "{ocr_text}\n",
        "\n",
        "[NORMAL_EXTRACTION]\n",
        "{normal_text}\n",
        "\n",
        "Please return the best possible, clean, organized Bangla text as described.\n",
        "\"\"\"\n",
        "\n",
        "    client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "      model=\"gpt-4.1-mini\",\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert at reconstructing and formatting Bangla educational documents.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "      ],\n",
        "      temperature=0.2,\n",
        "      max_tokens=2064\n",
        ")\n",
        "    cleaned_text = response.choices[0].message.content\n",
        "\n",
        "\n",
        "    # Save cleaned page\n",
        "    with open(f\"{cleaned_dir}/page_{i:03d}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(cleaned_text)\n",
        "    print(f\"✅ Cleaned page saved: page_{i:03d}.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4eFrtxXp35p",
        "outputId": "9a7343b2-e170-4a7d-9384-f90f8dfb20b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cleaned page saved: page_001.txt\n",
            "✅ Cleaned page saved: page_002.txt\n",
            "✅ Cleaned page saved: page_003.txt\n",
            "✅ Cleaned page saved: page_004.txt\n",
            "✅ Cleaned page saved: page_005.txt\n",
            "✅ Cleaned page saved: page_006.txt\n",
            "✅ Cleaned page saved: page_007.txt\n",
            "✅ Cleaned page saved: page_008.txt\n",
            "✅ Cleaned page saved: page_009.txt\n",
            "✅ Cleaned page saved: page_010.txt\n",
            "✅ Cleaned page saved: page_011.txt\n",
            "✅ Cleaned page saved: page_012.txt\n",
            "✅ Cleaned page saved: page_013.txt\n",
            "✅ Cleaned page saved: page_014.txt\n",
            "✅ Cleaned page saved: page_015.txt\n",
            "✅ Cleaned page saved: page_016.txt\n",
            "✅ Cleaned page saved: page_017.txt\n",
            "✅ Cleaned page saved: page_018.txt\n",
            "✅ Cleaned page saved: page_019.txt\n",
            "✅ Cleaned page saved: page_020.txt\n",
            "✅ Cleaned page saved: page_021.txt\n",
            "✅ Cleaned page saved: page_022.txt\n",
            "✅ Cleaned page saved: page_023.txt\n",
            "✅ Cleaned page saved: page_024.txt\n",
            "✅ Cleaned page saved: page_025.txt\n",
            "✅ Cleaned page saved: page_026.txt\n",
            "✅ Cleaned page saved: page_027.txt\n",
            "✅ Cleaned page saved: page_028.txt\n",
            "✅ Cleaned page saved: page_029.txt\n",
            "✅ Cleaned page saved: page_030.txt\n",
            "✅ Cleaned page saved: page_031.txt\n",
            "✅ Cleaned page saved: page_032.txt\n",
            "✅ Cleaned page saved: page_033.txt\n",
            "✅ Cleaned page saved: page_034.txt\n",
            "✅ Cleaned page saved: page_035.txt\n",
            "✅ Cleaned page saved: page_036.txt\n",
            "✅ Cleaned page saved: page_037.txt\n",
            "✅ Cleaned page saved: page_038.txt\n",
            "✅ Cleaned page saved: page_039.txt\n",
            "✅ Cleaned page saved: page_040.txt\n",
            "✅ Cleaned page saved: page_041.txt\n",
            "✅ Cleaned page saved: page_042.txt\n",
            "✅ Cleaned page saved: page_043.txt\n",
            "✅ Cleaned page saved: page_044.txt\n",
            "✅ Cleaned page saved: page_045.txt\n",
            "✅ Cleaned page saved: page_046.txt\n",
            "✅ Cleaned page saved: page_047.txt\n",
            "✅ Cleaned page saved: page_048.txt\n",
            "✅ Cleaned page saved: page_049.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdjU942DpIYj",
        "outputId": "3fbf6e73-8c29-4f4d-a999-ac41e6a4d48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pinecone sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEQHiqi2u46z",
        "outputId": "356cbe07-5e29-407e-9eb0-5808bdc8851b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.11/dist-packages (7.3.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (5.0.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2025.7.14)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (1.7.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.14.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PINECONE_API_KEY = \"pcsk_2czr3A_58ustdWMomnjZ7p1P3P5UaNPagR9h61WNiW6iAeXFiDkH3gWrNoqpbxFghTZYCY\""
      ],
      "metadata": {
        "id": "9OJmz7OUryId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Pinecone credentials\n",
        "PINECONE_API_KEY = \"pcsk_2czr3A_58ustdWMomnjZ7p1P3P5UaNPagR9h61WNiW6iAeXFiDkH3gWrNoqpbxFghTZYCY\"\n",
        "INDEX_NAME = \"bangla-book-index\"\n",
        "DIMENSION = 1024\n",
        "\n",
        "\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "\n",
        "if INDEX_NAME not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=INDEX_NAME,\n",
        "        dimension=DIMENSION,\n",
        "        metric='cosine',\n",
        "        spec=ServerlessSpec(\n",
        "             cloud=\"aws\",\n",
        "             region=\"us-east-1\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "#  Connect to index\n",
        "index = pc.Index(INDEX_NAME)\n",
        "\n",
        "# Load E5-large model\n",
        "model = SentenceTransformer('intfloat/multilingual-e5-large')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480,
          "referenced_widgets": [
            "9b39e4c039a449e8ade0488d69227a63",
            "cb711231a1ad463b8245ccd537316792",
            "9ecbbb166b7f4d648764b6e8b5d3da3c",
            "97e45ada7bfe41b9bd437c47541c0eac",
            "b77ba70cb25b434fa91956392de1bc19",
            "3abf57889b8141028192c45c64a0cd93",
            "3fff86766a834f5a92b657367f394ac7",
            "99e9bc24ded74c8594f5c82e6670670a",
            "63c3dcdb004d4818a44edec4f2748669",
            "c1399d64e61b44b0af38f1e36c379893",
            "75df7d1eaacd43d79f85b3bc5a8aaec7",
            "5fb70fcb101d4164a837526aca83c1ea",
            "d113ee8f311b446fb5c63c2e2e878b49",
            "b958ca12999347279e08ea0d90c6334a",
            "6086563d0a1a491aaf2dd9a15e46be8c",
            "62e79e9cc25a4a56a366ed21a8c190e8",
            "5d7ddf36ddf341ca830620c2eaa8aebe",
            "364c225a2698432bad5bc6c5d7bea58d",
            "f580757874df4f79b5cf51db9ca92afb",
            "15a89adf68454e518bf35e9d9e876d27",
            "a339a42821b344cdb755554924afbe00",
            "339da41940684de686075cae31c7e0d3",
            "59e31824e2cb43ebad2a84c9ed1e2840",
            "1a25029be6ff45bb85183292d4dc1047",
            "2e31f70287f14e4cb7cf759613b551aa",
            "c44f91a548ab41a9a1537cd768e71423",
            "bdcd421177f142d19d3243a268378312",
            "09ed0738644c4cfb9975b621fe54050a",
            "4f64205942a24083a08b3857b4105424",
            "f34556175f5a443dae0844eec9c7c4f5",
            "18fa6f80e70c4bccbbcbd714fa7b48d5",
            "cf89ebc0aeb94fd083940bb4f86469c7",
            "83c585f21c6341a0836e52760f102d59",
            "6a9e42a957724396b2d0987e0f5111e1",
            "f5bb7fe107f345fe8f800781bba10f90",
            "ad1bc764643245b9ba46ac6972db63bb",
            "ac93e4f897984380843f1c98efbdfa92",
            "313b280845544fa8bc4b53dc4e874325",
            "b499b646afdd4d72816413981d43f202",
            "1a47178b62834bf494bd0141f40da108",
            "cb39bd8417ef4a569302496476a6ff84",
            "004d9877c723457188382d7cd4e766da",
            "c7081caaa5d447e894b1f7cf27561c1d",
            "9aa6bd78dd794b819f2736d103b3ded5",
            "ccfb3d61d90849d486f54e726e0cfb77",
            "b5f00f1366174c4ab28e4ef978cbcd97",
            "991102ac69004f4ca1e06439f119f01e",
            "0a1abf99d0c54461b56616f39849f4ef",
            "c577e9ecaa9f491ab1095548f6d5af6e",
            "a59037c71424465fb1a2add1e0f72a31",
            "525eaa0dc8a745ffa788725c77f47b74",
            "e5f41f0f7bc544d4a3fc5b2af5d81641",
            "cc2d1b9aaea24f119feac600022c23f7",
            "9a5e7b73ed824b57a23238d448276397",
            "aaadae20c32f4fca8055daf3655370cd",
            "5e6b482e17954a1192c2a316bcc15b2e",
            "0ed81db31b4643d0bf4a43fdb66143ac",
            "8f26e69b38094a4bacde66f3be9c7478",
            "086f38e980f14012b0b6c5bacf3bc86b",
            "707d2a10c84e493a9b282762c52895db",
            "04fc1b6f287c4f5eaa8bfe1492478b53",
            "bd8ad1c970684fb680f4166711fb45e9",
            "99a776af048249b79f1b41e2f3c98fec",
            "29c2d89462d94cd8b7dd7e05206969f1",
            "6070f7f258434ef4a126362ee76cf329",
            "0647eec5276a4fc1885f12473089b693",
            "cb7b5ba588c44352be2efc645d08c1fc",
            "8b8234defd784a44a793ad6aa226f03e",
            "5a2e081ca1a34151837c346a17a8827d",
            "10eeb0939d4444d8b7f33071aa00ed2e",
            "466a20ad2e4f4ef0972ee1938748a903",
            "0fc4ae721ce549efa58fbaeae0266ec9",
            "fbf8d67ac9024b34a12a98fdcde961c1",
            "1fbf57ff144a46cf8862c623a72baaed",
            "d0410c810e4c4bbfbb4c92c84b204fa2",
            "b71f9e5fa8cd4a36bb58d93fc24ab64c",
            "9988a9a957fb45c39f1c65c5ac06508d",
            "dd2609df55bb431a94841748a0adf01f",
            "5ac9b2b54bfb41d0b9b6f860c7714a06",
            "2aba343cbcc04470940b97afebde4d20",
            "a073299ffecc4429b425175384b46e93",
            "84614270de34413180628dd1da45518e",
            "c1651f9d71e74cafb70e9415acd09968",
            "11b64993319741c688fa636601f00430",
            "0cb03da93ba046cfa86d494605e2983e",
            "ed24429107824ea3a6b4a8a9f9970427",
            "fedd0efbcf9c4a0791cbdb72820be41a",
            "1c1f44bbba22406a9cd3cd22c6022595",
            "53afcc71f1ba4c9790f5fd3f06c2da5e",
            "a1994e2e045b41f5aec930ddacdd4204",
            "b54462e5b1bf40539c4678eb62766b14",
            "a180aedbcad94b6389b768337896b748",
            "e5dd0c514fca4882b6bf19119eecb17c",
            "13655fd2f4c1454298be898a0c9a6b40",
            "1029a3fe68db45dd9ca735cc2667a092",
            "de0a23fd4af34fbdb4d1e1d45ddd668f",
            "b789aa69180e4bf3b1264274e0a51411",
            "7f744d7c4868422e9c8e94d5ec55e8ce",
            "9b4ef413ed1d42d8b71437225e0ff5f1",
            "8b5ce748398347cc99dc117395bf2e5f",
            "1f8826b0f046410c852c325ec052375f",
            "6f2fb7d867a140008dbb5d98650ba27f",
            "c344f04afc6a4203bfdc47f1ea053ecb",
            "d3673832895942f99fe9d699209e1462",
            "a6b39e9ba5774208bf41e6de563a1428",
            "1a199c56466a432a9f4d13f939545cbf",
            "abf15cec6dc04b809e7e1b8344c5497c",
            "afb354c54f1c408f88d3cdec91edb6e7",
            "befeda83979e4f2fa514b17e0a32f446",
            "d6a937d658834d69bf34679977fc0549"
          ]
        },
        "id": "ThhDUXugqJ8m",
        "outputId": "f4d0eaa6-8277-4bc7-bc87-10ddb8b5779e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b39e4c039a449e8ade0488d69227a63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fb70fcb101d4164a837526aca83c1ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59e31824e2cb43ebad2a84c9ed1e2840"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a9e42a957724396b2d0987e0f5111e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccfb3d61d90849d486f54e726e0cfb77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e6b482e17954a1192c2a316bcc15b2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb7b5ba588c44352be2efc645d08c1fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd2609df55bb431a94841748a0adf01f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53afcc71f1ba4c9790f5fd3f06c2da5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/201 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b5ce748398347cc99dc117395bf2e5f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLEANED_DIR = \"/content/drive/MyDrive/cleaned_pages\"\n",
        "chunks = []\n",
        "chunk_ids = []\n",
        "\n",
        "for fname in sorted(os.listdir(CLEANED_DIR)):\n",
        "    if fname.endswith(\".txt\"):\n",
        "        with open(os.path.join(CLEANED_DIR, fname), encoding=\"utf-8\") as f:\n",
        "            text = f.read().strip()\n",
        "            if text:\n",
        "                chunks.append(text)\n",
        "                chunk_ids.append(fname.replace('.txt', ''))  # e.g., 'page_001'\n",
        "\n",
        "embeddings = model.encode(\n",
        "    [f\"passage: {chunk}\" for chunk in chunks],\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cd5d3419d989429aa478c479b908e9db",
            "b5183b818e8d41f29596e2250fbc8ded",
            "cd4ccb01d4344ebeb53e4dcbdf082595",
            "f8e739bef3224e1ca1ec70ec158ef2f9",
            "920510c0f1324823bec76d255ea50aca",
            "5add6fe662874f8cbdbe3dd0bfa94a31",
            "b44bb22d46e34a038a81f731b27a8cae",
            "51ba350ca7ac4043bf9d15e45cfdc6d5",
            "9788ac54b06541358b179cd90ed38ad2",
            "40a20d43caa4486ea9c2dac30cc3a9e4",
            "f70544aeebc744f68f9e53a57d4d0a77"
          ]
        },
        "id": "q3OXS910qJ_3",
        "outputId": "3bf7e3a5-a17b-42ca-ecae-f8f0c830459a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd5d3419d989429aa478c479b908e9db"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for i in range(0, len(chunks), batch_size):\n",
        "    batch_ids = chunk_ids[i:i+batch_size]\n",
        "    batch_embs = embeddings[i:i+batch_size]\n",
        "    batch_texts = chunks[i:i+batch_size]\n",
        "    pinecone_vectors = [\n",
        "        (batch_ids[j], batch_embs[j].tolist(), {\"text\": batch_texts[j]})\n",
        "        for j in range(len(batch_ids))\n",
        "    ]\n",
        "    index.upsert(vectors=pinecone_vectors)\n",
        "    print(f\"✅ Upserted batch {i // batch_size + 1}\")\n",
        "\n",
        "print(\"🎉 All cleaned chunks embedded and uploaded to Pinecone!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH5FgoUlqKCV",
        "outputId": "1f6fe363-d96c-4c5f-8217-cc3bd6c42c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Upserted batch 1\n",
            "✅ Upserted batch 2\n",
            "🎉 All cleaned chunks embedded and uploaded to Pinecone!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ez76QFF-qKKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MThgcWf0pIj5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}