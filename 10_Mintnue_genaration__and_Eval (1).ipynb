{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_I4sYnl6vFT",
        "outputId": "2a4bc5b7-4c35-4347-9cf8-c90b8c07443f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pinecone in /usr/local/lib/python3.11/dist-packages (7.3.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (5.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.97.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2025.7.14)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (1.7.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.14.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: nvidia-cudnn-cu12\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed nvidia-cudnn-cu12\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (5.0.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.7.14)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: nvidia-cudnn-cu12\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed nvidia-cudnn-cu12\n"
          ]
        }
      ],
      "source": [
        "!pip install -U pinecone sentence-transformers openai\n",
        "!pip install openai --quiet\n",
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pinecone import Pinecone\n",
        "import openai\n",
        "import pandas as pd\n",
        "\n",
        "# 3. Pinecone and OpenAI setup\n",
        "PINECONE_API_KEY = \"pcsk_2czr3A_58ustdWMomnjZ7p1P3P5UaNPagR9h61WNiW6iAeXFiDkH3gWrNoqpbxFghTZYCY\"\n",
        "INDEX_NAME = \"bangla-book-index\"\n",
        "REGION = \"us-east-1\"\n",
        "\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "index = pc.Index(INDEX_NAME)\n",
        "\n",
        "model = SentenceTransformer('intfloat/multilingual-e5-large')\n",
        "import os\n",
        "openai.api_key =\"\"\n",
        "\n",
        "chat_history = []\n",
        "def answer_from_book(user_query, top_k=5):\n",
        "    global chat_history\n",
        "\n",
        "    # Keep only last 10 turns\n",
        "    if len(chat_history) > 10:\n",
        "        chat_history = chat_history[-10:]\n",
        "\n",
        "    # Prepare chat history string for LLM\n",
        "    history_str = \"\"\n",
        "    for turn in chat_history:\n",
        "        history_str += f\"User: {turn['user']}\\nAssistant: {turn['assistant']}\\n\"\n",
        "\n",
        "    # RAG retrieval\n",
        "    query_emb = model.encode(f\"query: {user_query}\")\n",
        "    results = index.query(\n",
        "        vector=query_emb.tolist(),\n",
        "        top_k=top_k,\n",
        "        include_metadata=True\n",
        "    )\n",
        "    retrieved_chunks = [match['metadata']['text'] for match in results['matches']]\n",
        "    context = \"\\n\\n\".join([f\"[Passage {i+1}]\\n{chunk}\" for i, chunk in enumerate(retrieved_chunks)])\n",
        "    #  LLM prompt\n",
        "\n",
        "    llm_prompt = f\"\"\"\n",
        "\n",
        "You are a Bangla QA assistant for textbooks. The question can be asked in both english or bangla but you need to answer in bangla.it in Bangla.\n",
        "\n",
        "Below is the recent conversation history. Use it for context if needed:\n",
        "{history_str}\n",
        "\n",
        "You have been provided with several retrieved passages from a textbook. These passages may include:\n",
        "- Explanatory or narrative text (main passages)\n",
        "- Tables\n",
        "- MCQ (multiple choice questions) and their options or answer keys\n",
        "- Lists and other formatted content\n",
        "\n",
        "**Instructions:**\n",
        "1. **If the question includes the word 'বাগধারাটি', first look for an answer in the word meaning section (such as sections titled 'বাগধারা', 'বাগধারার অর্থ', or where word meanings are explained).**\n",
        "2. **First, carefully read the main explanatory/narrative passages. Try to find the answer to the user's question in these main text sections.**\n",
        "3. **If you do not find the answer in the passages, then check the MCQ, option lists, tables, or answer keys in the retrieved text.**\n",
        "4. If you still cannot find the answer, reply only with: 'Not found in the book.' Never make up information or use outside knowledge.\n",
        "\n",
        "If multiple sources in the passages or MCQ part provide relevant details, synthesize the answer based on all of them.\n",
        "\n",
        "\n",
        "Below are some examples:\n",
        "\n",
        "User Question: অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?\n",
        "Expected Answer: শুম্ভুনাথ\n",
        "\n",
        "User Question: কাকে অনুপমের ভাগ্য দেবতা বলে উল্লেখ করা হয়েছে?\n",
        "Expected Answer: মামাকে\n",
        "\n",
        "User Question: বিয়ের সময় কল্যাণীর প্রকৃত বয়স কত ছিল?\n",
        "Expected Answer: ১৫ বছর\n",
        "\n",
        "Here are the most relevant passages:\n",
        "{context}\n",
        "\n",
        "Answer the following question using ONLY the information in the passages above.\n",
        "\n",
        "Question: {user_query}\n",
        "\"\"\"\n",
        "    # LLM call\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert educational QA assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": llm_prompt}\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "        max_tokens=512\n",
        "    )\n",
        "    answer = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Add turn to chat history\n",
        "    chat_history.append({\"user\": user_query, \"assistant\": answer})\n",
        "\n",
        "    # Again keep only last 10\n",
        "    if len(chat_history) > 10:\n",
        "        chat_history = chat_history[-10:]\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vDLhPTVw682U"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Example usage:\n",
        "q = \" Who was Anupam?\"\n",
        "print(answer_from_book(q))\n",
        "\n"
      ],
      "metadata": {
        "id": "iQDJfCT8Ddet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = \" how was horish define in book?\"\n",
        "print(answer_from_book(q))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI5CqEtmSHAj",
        "outputId": "1eefdae3-3b8b-4d33-8e60-cbcdae7c7120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "হরিশকে বইয়ে এমন একজন চরিত্র হিসেবে বর্ণনা করা হয়েছে যিনি সাহসী, উচ্ছল এবং রসিক স্বভাবের। উদ্দীপকে উল্লেখ আছে যে শাফিক নামের চরিত্রটি যাকে হরিশের সঙ্গে তুলনা করা হয়েছে, সে যেকোনো পরিবেশে দ্রুত নিজেকে মানিয়ে নিতে পারে এবং আলোচনার মধ্যমণি হয়ে ওঠে। এছাড়া, 'অপরিচিতা' গল্পে হরিশের গুণ হিসেবে আসর জমানোর ক্ষমতা উল্লেখ আছে। তাই হরিশকে সাহসিকতা, ব্যক্তিত্ব এবং রসিকতার সমন্বয়ে গড়ে উঠা একজন প্রাণবন্ত ও সক্রিয় চরিত্র হিসেবে দেখা যায়।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVWpc90hMGO9",
        "outputId": "8cabc2b9-9fe4-44e6-9474-8bdbaa187747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pandas as pd\n",
        "\n",
        "# question-answer pairs (can use DataFrame or dict)\n",
        "qa_pairs = [\n",
        "    {\"question\": \"‘মাকাল ফল’ বাগধারাটি কী বোঝাতে ব্যবহৃত হয়েছে?\", \"answer\": \"বাহ্যিকভাবে সুন্দর কিন্তু মূল্যহীন\"},\n",
        "    {\"question\": \"‘অপরিচিতা' গল্পটি প্রথম কোথায় প্রকাশিত হয়?\", \"answer\": \"সবুজপত্র\"},\n",
        "    {\"question\": \"হরিশি কোথায় কর্মরত ছিলেন?\", \"answer\": \"কানপুর\"},\n",
        "    {\"question\": \"অনুপমের প্রকৃত অভিভাবক কে?\", \"answer\": \"মামা\"},\n",
        "    {\"question\": \"এসপাস-ওসপাস' বাগধারাটির অর্থ কী?\", \"answer\": \"একে অপরকে দোষারোপ\"},\n",
        "    {\"question\": \"‘অপরিচিতা’ গল্পে অনুপমের আত্মপরিচয় কীভাবে ফুটে ওঠে?\", \"answer\": \"নীরবতা ও আত্মদ্বন্দ্বে\"},\n",
        "    {\"question\": \"মন্দ নয়, খাঁটি সোনা বলতে হয়’ — এই উক্তিটি কে বলেন?\", \"answer\": \"বিনুদাদা\"},\n",
        "    {\"question\": \"‘অপরিচিতা' গল্পে অনুপমের বয়স কত ছিল?\", \"answer\": \"২৭\"},\n",
        "    {\"question\": \"‘অপরিচিতা’ গল্পে অনুপম কী নিয়ে দ্বিধায় ভোগে?\", \"answer\": \"আত্মসম্মান\"},\n",
        "    {\"question\": \"অনুপমকে প্রথম যে মেয়েটি প্রত্যাখ্যান করে, সে কে?\", \"answer\": \"অনুপমকে প্রথম যে মেয়েটি প্রত্যাখ্যান করে, তিনি হলেন কল্যাণী।\"},\n",
        "    {\"question\": \"হরিশিকে ‘অপরিচিতা’ গল্পে কীভাবে চিহ্নিত করা হয়েছে?\", \"answer\": \"রসিক মনের মানুষ\"},\n",
        "]\n",
        "\n",
        "\n",
        "e5_model = SentenceTransformer('intfloat/multilingual-e5-large')\n",
        "\n",
        "results = []\n",
        "\n",
        "#compute cosine similarity\n",
        "for qa in qa_pairs:\n",
        "    question = qa['question']\n",
        "    ground_truth = qa['answer']\n",
        "\n",
        "    llm_answer = answer_from_book(question)\n",
        "    print(f\"\\nQ: {question}\")\n",
        "    print(f\"LLM Answer: {llm_answer}\")\n",
        "    print(f\"Expected: {ground_truth}\")\n",
        "\n",
        "    # Compute semantic similarity\n",
        "    emb1 = e5_model.encode(ground_truth, convert_to_tensor=True)\n",
        "    emb2 = e5_model.encode(llm_answer, convert_to_tensor=True)\n",
        "    score = util.pytorch_cos_sim(emb1, emb2).item()\n",
        "\n",
        "    print(f\"Cosine Similarity: {score:.4f}\")\n",
        "\n",
        "    # Collect results for DataFrame or CSV\n",
        "    results.append({\n",
        "        \"question\": question,\n",
        "        \"ground_truth\": ground_truth,\n",
        "        \"llm_answer\": llm_answer,\n",
        "        \"cosine_similarity\": score\n",
        "    })\n",
        "\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"/content/drive/MyDrive/rag_eval_results.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "tv9KoECGL6lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "qa_pairs = [\n",
        "    {\"question\": \"‘মাকাল ফল’ বাগধারাটি কী বোঝাতে ব্যবহৃত হয়েছে?\", \"answer\": \"বাহ্যিকভাবে সুন্দর কিন্তু মূল্যহীন\"},\n",
        "    {\"question\": \"‘অপরিচিতা' গল্পটি প্রথম কোথায় প্রকাশিত হয়?\", \"answer\": \"সবুজপত্র\"},\n",
        "    {\"question\": \"হরিশি কোথায় কর্মরত ছিলেন?\", \"answer\": \"কানপুর\"},\n",
        "    {\"question\": \"অনুপমের প্রকৃত অভিভাবক কে?\", \"answer\": \"মামা\"},\n",
        "    {\"question\": \"এসপাস-ওসপাস' বাগধারাটির অর্থ কী?\", \"answer\": \"একে অপরকে দোষারোপ\"},\n",
        "    {\"question\": \"‘অপরিচিতা’ গল্পে অনুপমের আত্মপরিচয় কীভাবে ফুটে ওঠে?\", \"answer\": \"নীরবতা ও আত্মদ্বন্দ্বে\"},\n",
        "    {\"question\": \"মন্দ নয়, খাঁটি সোনা বলতে হয়’ — এই উক্তিটি কে বলেন?\", \"answer\": \"বিনুদাদা\"},\n",
        "    {\"question\": \"‘অপরিচিতা' গল্পে অনুপমের বয়স কত ছিল?\", \"answer\": \"২৬\"},\n",
        "    {\"question\": \"‘অপরিচিতা’ গল্পে অনুপম কী নিয়ে দ্বিধায় ভোগে?\", \"answer\": \"আত্মসম্মান\"},\n",
        "    {\"question\": \"অনুপমকে প্রথম যে মেয়েটি প্রত্যাখ্যান করে, সে কে?\", \"answer\": \"অনুপমকে প্রথম যে মেয়েটি প্রত্যাখ্যান করে, তিনি হলেন কল্যাণী।\"},\n",
        "    {\"question\": \"হরিশিকে ‘অপরিচিতা’ গল্পে কীভাবে চিহ্নিত করা হয়েছে?\", \"answer\": \"রসিক মনের মানুষ\"},\n",
        "]\n",
        "\n",
        "\n",
        "e5_model = SentenceTransformer('intfloat/multilingual-e5-large')\n",
        "\n",
        "def rag_relevance_eval(qa_pairs, k=5, sim_threshold=0.7):\n",
        "    relevant_count = 0\n",
        "    all_results = []\n",
        "\n",
        "    for qa in qa_pairs:\n",
        "        question = qa['question']\n",
        "        ground_truth = qa['answer']\n",
        "\n",
        "        # Get top-K retrieved chunks\n",
        "        query_emb = e5_model.encode(f\"query: {question}\")\n",
        "        results = index.query(\n",
        "            vector=query_emb.tolist(),\n",
        "            top_k=k,\n",
        "            include_metadata=True\n",
        "        )\n",
        "        retrieved_chunks = [match['metadata']['text'] for match in results['matches']]\n",
        "\n",
        "        # 1. String match\n",
        "        found = any(ground_truth in chunk for chunk in retrieved_chunks)\n",
        "        found_method = 'string' if found else None\n",
        "        max_sim = 0\n",
        "\n",
        "        # Semantic similarity if not found by string\n",
        "        if not found:\n",
        "            gt_emb = e5_model.encode(ground_truth, convert_to_tensor=True)\n",
        "            for chunk in retrieved_chunks:\n",
        "                chunk_emb = e5_model.encode(chunk, convert_to_tensor=True)\n",
        "                sim = util.pytorch_cos_sim(gt_emb, chunk_emb).item()\n",
        "                if sim > max_sim:\n",
        "                    max_sim = sim\n",
        "            if max_sim >= sim_threshold:\n",
        "                found = True\n",
        "                found_method = 'semantic'\n",
        "            else:\n",
        "                found_method = None\n",
        "\n",
        "        if found:\n",
        "            relevant_count += 1\n",
        "\n",
        "        all_results.append({\n",
        "            \"question\": question,\n",
        "            \"ground_truth\": ground_truth,\n",
        "            \"retrieved_chunks\": \" ||| \".join(retrieved_chunks),\n",
        "            \"relevant\": found,\n",
        "            \"found_by\": found_method,\n",
        "            \"max_semantic_sim\": max_sim if found_method == 'semantic' else 1.0 if found_method == 'string' else max_sim\n",
        "        })\n",
        "\n",
        "        print(f\"Q: {question}\\nFound in top-{k} chunks: {found} (method: {found_method}) | Max sim: {max_sim:.3f}\")\n",
        "\n",
        "    relevance_score = relevant_count / len(qa_pairs)\n",
        "    print(f\"\\nRAG Retriever Relevance Score: {relevance_score:.2%} (Found answer in {relevant_count} out of {len(qa_pairs)} queries)\")\n",
        "    return all_results, relevance_score\n",
        "\n",
        "\n",
        "results, score = rag_relevance_eval(qa_pairs, k=5)\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "csv_path = \"/content/drive/MyDrive/rag_relevance_eval_results.csv\"\n",
        "df.to_csv(csv_path, index=False)\n",
        "print(f\"\\nResults saved to {csv_path}\")\n"
      ],
      "metadata": {
        "id": "sCXJSQ-YT3hR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}